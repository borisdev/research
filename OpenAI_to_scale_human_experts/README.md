# How can OpenAI be used as a tool to scale human subject matter experts in order to train ML-NLP models faster?

# Consulting: Human-in-the-Loop annotation design for ML 

## Promotional ideas 

We are looking for companies whose AI project is stuck because of garbage input data.

Bad prediction performance can't be fixed with sophisticated ML R&D when the training data is garbage.

### Potential Google Ads

- garbage in, garbage out
- labeling quality
- does your pipeline require heavy manual work before data releases?
- lots of labeling but still poor predictions?
- data quagmire rescue
- data pipelines get clogged with garbage input
- Mr CEO, How much $ have you burned on your AI project?
- if benchmark met, max you pay is .33 of what was burned b4 starting the project

### Landing pages


### Misc ideas

- Free consultation
- Cost = 1/3 of the $$$ you have burned
- Don't contact us unless you have already failed.

## Success factors

- the story of past failure

## Tools

- A new process of using OpenAI to absorb SME and to reduce labeling ?
- pre-procesing noise filters like schema validation
- QA and QC
- exploratory stats

## People

- Robert
- Boris
- ???

## Experiments

- Is this dish Keto?
- Is this sentence VAGUE?
- Does this invoice line relate to a ADMIN task?   
- Is this Medium article relevant to me?
- AIWORK https://aiwork.io/

## Notes based on chat with Shawn Feb 3

- [Snorkle AI](https://snorkel.ai/) -- checkout videos from conferences
-- Programmatic Labeling
-- Foundational Models
-- Use Case Examples
- Data centric AI
- Get paid based on how far we beat benchmark
- Stuggling NLP
- C-suite level access needed to get traction
- Leveraging Foundational Model - Fine-tune
- Functions
- Weak labeling
- Weak supervision

